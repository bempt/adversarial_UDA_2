{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # free port 6006 for tensorboard\n",
    "# !fuser 6006/tcp -k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# import os\n",
    "\n",
    "# # packages\n",
    "# !pip install -q segmentation-models-pytorch\n",
    "# !pip install -q torchsummary\n",
    "# !pip install pytorch-adapt\n",
    "\n",
    "# # mount drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# # download git repo\n",
    "# !git clone https://'bempt':'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'@github.com/bempt/Adversarial_UDA.git\n",
    "\n",
    "# # Get the current directory\n",
    "# current_dir = os.getcwd()\n",
    "\n",
    "# # Check if the current directory is not '/content/Adversarial_UDA'\n",
    "# if current_dir != '/content/Adversarial_UDA':\n",
    "#     # Change to the '/content/Adversarial_UDA' directory\n",
    "#     os.chdir('/content/Adversarial_UDA')\n",
    "\n",
    "# # make checkpoints dir\n",
    "# !mkdir -p checkpoints/adversarial\n",
    "# !mkdir -p checkpoints/segmentation\n",
    "\n",
    "# # download data\n",
    "# kaggle_token = 'kaggle.json'\n",
    "# with open(kaggle_token, \"w\") as f:\n",
    "#             json.dump({\"username\":\"bennettnewhook\",\n",
    "#                        \"key\":\"d4d6dbe590ee043d03d95e86dde3ef43\"}, f)\n",
    "# !rm -r ~/.kaggle\n",
    "# !mkdir ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d bulentsiyah/semantic-drone-dataset\n",
    "\n",
    "# # unzip data\n",
    "# UNZIP_PATH = './data/semantic-drone/'\n",
    "# !mkdir -p {UNZIP_PATH}\n",
    "# !unzip semantic-drone-dataset.zip -d {UNZIP_PATH}\n",
    "\n",
    "# Holyrood\n",
    "# symlink stored under school/research/bennett_datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# free port 6006 for tensorboard\n",
    "!fuser 6006/tcp -k"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this notebook to run with updated APIs, we need torch 1.12+ and torchvision 0.13+\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision\n",
    "    assert int(torch.__version__.split(\".\")[1]) >= 12, \"torch version should be 1.12+\"\n",
    "    assert int(torchvision.__version__.split(\".\")[1]) >= 13, \"torchvision version should be 0.13+\"\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")\n",
    "except:\n",
    "    print(f\"[INFO] torch/torchvision versions not as required, installing nightly versions.\")\n",
    "    !pip3 install -U torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113\n",
    "    import torch\n",
    "    import torchvision\n",
    "    print(f\"torch version: {torch.__version__}\")\n",
    "    print(f\"torchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue with regular imports\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "from torch import nn\n",
    "from torchvision import transforms\n",
    "\n",
    "# Try to get torchinfo, install it if it doesn't work\n",
    "try:\n",
    "    from torchinfo import summary\n",
    "except:\n",
    "    print(\"[INFO] Couldn't find torchinfo... installing it.\")\n",
    "    !pip install -q torchinfo\n",
    "    from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modular.utils import set_device, set_seeds\n",
    "\n",
    "device = set_device()\n",
    "seed = set_seeds()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "SUP_VAL_SPLIT = 0.15\n",
    "SUP_TEST_SPLIT = 0.1\n",
    "SUP_IMAGE_PATH = './data/semantic-drone/dataset/semantic_drone_dataset/original_images/'\n",
    "SUP_MASK_PATH = './data/semantic-drone/dataset/semantic_drone_dataset/label_images_semantic/'\n",
    "\n",
    "# Model\n",
    "## Segmentation\n",
    "### Pretrained\n",
    "BACKBONE = 'resnet50'\n",
    "ENCODER_WEIGHTS = 'imagenet'\n",
    "ACTIVATION = None\n",
    "ENCODER_DEPTH = 5\n",
    "DECODER_CHANNELS = [256, 128, 64, 32, 16]\n",
    "MEAN=[0.485, 0.456, 0.406]\n",
    "STD=[0.229, 0.224, 0.225]\n",
    "### Optimizer\n",
    "MAX_LR = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "\n",
    "# Train\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 2\n",
    "NUM_WORKERS_RATIO = 0.6"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modular.segmentation import data_setup_segmentation\n",
    "\n",
    "# Split data\n",
    "sup_df, sup_img_count = data_setup_segmentation.create_df(SUP_IMAGE_PATH)\n",
    "X_trainval, X_test, X_train, X_val = data_setup_segmentation.split_data_supervised(sup_df, SUP_VAL_SPLIT, SUP_TEST_SPLIT, seed)\n",
    "data_setup_segmentation.data_size(sup_img_count, X_train, X_val, X_test)\n",
    "\n",
    "# Sample image and mask\n",
    "example_file_id = 100\n",
    "data_setup_segmentation.mask_over_image(sup_df, example_file_id, SUP_IMAGE_PATH, SUP_MASK_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from modular.segmentation import data_setup_segmentation as seg_data\n",
    "import os\n",
    "\n",
    "train_set_seg, val_set_seg, test_set_seg = seg_data.make_datasets(SUP_IMAGE_PATH, SUP_MASK_PATH,\n",
    "                                                                  X_train, X_val, X_test,\n",
    "                                                                  MEAN, STD,\n",
    "                                                                  seg_data.t_train, seg_data.t_val, seg_data.t_test,\n",
    "                                                                  )\n",
    "\n",
    "train_loader_seg, val_loader_seg, test_loader_seg = seg_data.make_dataloaders(train_set_seg, val_set_seg, test_set_seg,\n",
    "                                                                          BATCH_SIZE,\n",
    "                                                                          NUM_WORKERS_RATIO,\n",
    "                                                                          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "seg_model = smp.Unet(BACKBONE,\n",
    "                    encoder_weights=ENCODER_WEIGHTS,\n",
    "                    classes=seg_data.N_CLASSES,\n",
    "                    activation=ACTIVATION,\n",
    "                    encoder_depth=ENCODER_DEPTH,\n",
    "                    decoder_channels=DECODER_CHANNELS\n",
    "                    ).to(device)\n",
    "\n",
    "# View the output of the model\n",
    "# seg_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss and optimizer\n",
    "loss_seg = nn.CrossEntropyLoss()\n",
    "optimizer_seg = torch.optim.AdamW(seg_model.parameters(),\n",
    "                                            lr=MAX_LR,\n",
    "                                            weight_decay=WEIGHT_DECAY\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Freeze all base layers by setting requires_grad attribute to False\n",
    "# for param in model.features.parameters():\n",
    "#     param.requires_grad = False\n",
    "    \n",
    "# # Since we're creating a new layer with random weights (torch.nn.Linear), \n",
    "# # let's set the seeds\n",
    "# set_seeds() \n",
    "\n",
    "# # Update the classifier head to suit our problem\n",
    "# model.classifier = torch.nn.Sequential(\n",
    "#     nn.Dropout(p=0.2, inplace=True),\n",
    "#     nn.Linear(in_features=1280, \n",
    "#               out_features=len(class_names),\n",
    "#               bias=True).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchinfo import summary\n",
    "\n",
    "# # # Get a summary of the model (uncomment for full output)\n",
    "# summary(seg_model, \n",
    "#         input_size=(BATCH_SIZE, 3, 256, 256), # make sure this is \"input_size\", not \"input_shape\" (batch_size, color_channels, height, width)\n",
    "#         verbose=0,\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modular.segmentation.engine_segmentation as engine_segmentation\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Create a writer with all default settings\n",
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': # prevents the crashing of multiprocessing (num_workers_ratio)\n",
    "    seg_results = engine_segmentation.train(model=seg_model,\n",
    "                    train_dataloader=train_loader_seg,\n",
    "                    val_dataloader=val_loader_seg,\n",
    "                    optimizer=optimizer_seg,\n",
    "                    loss_fn=loss_seg,\n",
    "                    epochs=EPOCHS,\n",
    "                    device=device,\n",
    "                    writer=writer)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download 10 percent and 20 percent training data (if necessary)\n",
    "data_10_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\",\n",
    "                                     destination=\"pizza_steak_sushi\")\n",
    "\n",
    "data_20_percent_path = download_data(source=\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\",\n",
    "                                     destination=\"pizza_steak_sushi_20_percent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training directory paths\n",
    "train_dir_10_percent = data_10_percent_path / \"train\"\n",
    "train_dir_20_percent = data_20_percent_path / \"train\"\n",
    "\n",
    "# Setup testing directory paths (note: use the same test dataset for both to compare the results)\n",
    "test_dir = data_10_percent_path / \"test\"\n",
    "\n",
    "# Check the directories\n",
    "print(f\"Training directory 10%: {train_dir_10_percent}\")\n",
    "print(f\"Training directory 20%: {train_dir_20_percent}\")\n",
    "print(f\"Testing directory: {test_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Create a transform to normalize data distribution to be inline with ImageNet\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], # values per colour channel [red, green, blue]\n",
    "                                 std=[0.229, 0.224, 0.225]) # values per colour channel [red, green, blue]\n",
    "\n",
    "# Compose transforms into a pipeline\n",
    "simple_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), # 1. Resize the images\n",
    "    transforms.ToTensor(), # 2. Turn the images into tensors with values between 0 & 1\n",
    "    normalize # 3. Normalize the images so their distributions match the ImageNet dataset \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 10% training and test DataLoaders\n",
    "train_dataloader_10_percent, test_dataloader, class_names = data_setup_multiclass_food.create_dataloaders(train_dir=train_dir_10_percent,\n",
    "    test_dir=test_dir, \n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Create 20% training and test data DataLoders\n",
    "train_dataloader_20_percent, test_dataloader, class_names = data_setup_multiclass_food.create_dataloaders(train_dir=train_dir_20_percent,\n",
    "    test_dir=test_dir,\n",
    "    transform=simple_transform,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "# Find the number of samples/batches per dataloader (using the same test_dataloader for both experiments)\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 10 percent training data: {len(train_dataloader_10_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in 20 percent training data: {len(train_dataloader_20_percent)}\")\n",
    "print(f\"Number of batches of size {BATCH_SIZE} in testing data: {len(train_dataloader_10_percent)} (all experiments will use the same test set)\")\n",
    "print(f\"Number of classes: {len(class_names)}, class names: {class_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import modular.model_builder_segmentation as model_builder_segmentation\n",
    "\n",
    "out_features = len(class_names)\n",
    "\n",
    "effnetb0 = model_builder_segmentation.create_effnetb0(out_features) \n",
    "effnetb2 = model_builder_segmentation.create_effnetb2(out_features)\n",
    "\n",
    "# # Get an output summary of the layers in our EffNetB0 feature extractor model (uncomment to view full output)\n",
    "# summary(model=effnetb0, \n",
    "#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "#         # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# ) \n",
    "\n",
    "## Get an output summary of the layers in our EffNetB2 feature extractor model (uncomment to view full output)\n",
    "# summary(model=effnetb2, \n",
    "#         input_size=(32, 3, 224, 224), # make sure this is \"input_size\", not \"input_shape\"\n",
    "#         # col_names=[\"input_size\"], # uncomment for smaller output\n",
    "#         col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "#         col_width=20,\n",
    "#         row_settings=[\"var_names\"]\n",
    "# ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create epochs list\n",
    "num_epochs = [5, 10]\n",
    "\n",
    "# 2. Create models list (need to create a new model for each experiment)\n",
    "models = [\"effnetb0\", \"effnetb2\"]\n",
    "\n",
    "# 3. Create dataloaders dictionary for various dataloaders\n",
    "train_dataloaders = {\"data_10_percent\": train_dataloader_10_percent,\n",
    "                     \"data_20_percent\": train_dataloader_20_percent}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# Create a writer with all default settings\n",
    "writer = SummaryWriter()\n",
    "\n",
    "from modular.utils import save_model, create_writer\n",
    "\n",
    "# 1. Set the random seeds\n",
    "set_seeds(seed=42)\n",
    "\n",
    "# 2. Keep track of experiment numbers\n",
    "experiment_number = 0\n",
    "\n",
    "# 3. Loop through each DataLoader\n",
    "for dataloader_name, train_dataloader in train_dataloaders.items():\n",
    "\n",
    "    # 4. Loop through each number of epochs\n",
    "    for epochs in num_epochs: \n",
    "\n",
    "        # 5. Loop through each model name and create a new model based on the name\n",
    "        for model_name in models:\n",
    "\n",
    "            # 6. Create information print outs\n",
    "            experiment_number += 1\n",
    "            print(f\"[INFO] Experiment number: {experiment_number}\")\n",
    "            print(f\"[INFO] Model: {model_name}\")\n",
    "            print(f\"[INFO] DataLoader: {dataloader_name}\")\n",
    "            print(f\"[INFO] Number of epochs: {epochs}\")  \n",
    "\n",
    "            # 7. Select the model\n",
    "            if model_name == \"effnetb0\":\n",
    "                model = model_builder.create_effnetb0(out_features) # creates a new model each time (important because we want each experiment to start from scratch)\n",
    "            else:\n",
    "                model = model_builder.create_effnetb2(out_features) # creates a new model each time (important because we want each experiment to start from scratch)\n",
    "            \n",
    "            # 8. Create a new loss and optimizer for every model\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            optimizer = torch.optim.Adam(params=model.parameters(), lr=0.001)\n",
    "\n",
    "            # 9. Train target model with target dataloaders and track experiments\n",
    "            engine.train(model=model,\n",
    "                  train_dataloader=train_dataloader,\n",
    "                  test_dataloader=test_dataloader, \n",
    "                  optimizer=optimizer,\n",
    "                  loss_fn=loss_fn,\n",
    "                  epochs=epochs,\n",
    "                  device=device,\n",
    "                  writer=create_writer(experiment_name=dataloader_name,\n",
    "                                       model_name=model_name,\n",
    "                                       extra=f\"{epochs}_epochs\"))\n",
    "            \n",
    "            # 10. Save the model to file so we can get back the best model\n",
    "            save_filepath = f\"07_{model_name}_{dataloader_name}_{epochs}_epochs.pth\"\n",
    "            save_model(model=model,\n",
    "                       target_dir=\"models\",\n",
    "                       model_name=save_filepath)\n",
    "            print(\"-\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check results in tensorboard\n",
    "# ## will error in VS Code, have to SHIFT CMD P and search for Python: Launch TensorBoard\n",
    "# %load_ext tensorboard # line magic to load TensorBoard\n",
    "# %tensorboard --logdir runs # run TensorBoard session with the \"runs/\" directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load best model, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
